\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\@newglossary{abbreviations}{glg-abr}{gls-abr}{glo-abr}
\providecommand\@glsxtr@savepreloctag[2]{}
\@newglossary{nomenclature}{nomenclature-glg}{nomenclature-gls}{nomenclature-glo}
\@newglossary{symbols}{symbols-glg}{symbols-gls}{symbols-glo}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{uw-ethesis.ist}
\@glsorder{word}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{iv}{section*.2}}
\citation{guo2017drmm}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{v}{section*.4}}
\citation{zhao2010term}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{intro}{{1}{1}{Introduction}{chapter.1}{}}
\newlabel{query-sent-example}{{1}{1}{Introduction}{chapter.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces An example of a query-text pair from the TREC Robust04 collection where a relevant piece of text does not contain direct query matches.}}{1}{figure.1.1}}
\citation{deerwester1990indexing}
\citation{mikolov2013distributed}
\citation{pennington2014glove}
\citation{peters2018deep}
\citation{radford2019language}
\citation{devlin2018bert}
\citation{guo2016deep}
\citation{yang2019simple}
\citation{nogueira2019passage}
\citation{Cormack:2009:RRF:1571941.1572114}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Contributions}{4}{section.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Thesis Organization}{4}{section.1.2}}
\citation{DBLP:journals/corr/LinzenDG16}
\citation{DBLP:journals/corr/abs-1803-11138}
\citation{peters2018deep}
\citation{peters2018deep}
\citation{melamud2016context2vec}
\citation{belinkov2017neural}
\citation{pennington2014glove}
\citation{peters2018deep}
\citation{rajpurkar2016squad}
\citation{socher2013recursive}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background and Related Work}{5}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Pretrained Language Models}{5}{section.2.1}}
\newlabel{lm}{{2.1}{5}{Pretrained Language Models}{section.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Feature-based Approaches}{5}{subsection.2.1.1}}
\citation{radford2019language}
\citation{wang2018glue}
\citation{vaswani2017attention}
\citation{radford2018improving}
\citation{zhu2015aligning}
\citation{devlin2018bert}
\citation{radford2019language}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Fine-tuning Approaches}{6}{subsection.2.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces BERT Models.}}{7}{figure.2.1}}
\newlabel{fig:bert}{{2.1}{7}{BERT Models}{figure.2.1}{}}
\citation{devlin2018bert}
\citation{vaswani2017attention}
\citation{zhu2015aligning}
\citation{wu2016google}
\citation{yang2019end}
\citation{nogueira2019passage}
\citation{jones2000probabilistic}
\citation{guo2017drmm}
\citation{huang2013learning}
\citation{shen2014learning}
\citation{huang2013learning}
\citation{guo2017drmm}
\citation{shen2014learning}
\citation{shen2014learning}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Document Retrieval}{9}{section.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Non-neural Document Retrieval}{9}{subsection.2.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Neural Document Retrieval}{9}{subsection.2.2.2}}
\newlabel{neural-retrieval}{{2.2.2}{9}{Neural Document Retrieval}{subsection.2.2.2}{}}
\citation{guo2017drmm}
\citation{xiong2017knrm}
\citation{mitra2017neural}
\citation{guo2017drmm}
\citation{xiong2017knrm}
\citation{mitra2017neural}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces \cite  {guo2017drmm}}}{10}{figure.2.2}}
\newlabel{fig:deep_matching}{{2.2}{10}{\cite {guo2017drmm}}{figure.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Representation-based Models}{10}{section*.8}}
\citation{lin2019neural}
\citation{lipton2018troubling}
\citation{sculley2018winner}
\citation{Yang_etal_SIGIR2019}
\citation{Yang:2018:ARR:3289400.3239571}
\citation{Cormack:2009:RRF:1571941.1572114}
\citation{zamani2018neural}
\@writefile{toc}{\contentsline {subsubsection}{Interaction-based Models}{11}{section*.9}}
\citation{guo2017drmm}
\citation{guo2016deep}
\citation{guo2016deep}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Experimental results applying neural models to rerank a strong baseline; $^{\dagger }$ indicates statistical significance.}}{12}{table.2.1}}
\newlabel{tab:exp-robust04}{{2.1}{12}{Experimental results applying neural models to rerank a strong baseline; $^{\dagger }$ indicates statistical significance}{table.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Contextualized Language Models}{12}{section*.10}}
\citation{nogueira2019passage}
\citation{yang2019simple}
\citation{zhang2018effective}
\citation{macavaney2019cedr}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces ...}}{13}{figure.2.3}}
\newlabel{fig:neural_robust04}{{2.3}{13}{..}{figure.2.3}{}}
\citation{Qiao:1904.07531:2019}
\citation{nogueira2019passage}
\citation{dai2018convolutional}
\citation{Padigela:1905.01758:2019}
\citation{joachims2002optimizing}
\citation{xiong2017knrm}
\citation{dai2018convolutional}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Evaluation Metrics}{14}{section.2.3}}
\citation{manning2010introduction}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Mean Average Precision (MAP)}{15}{subsection.2.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Precision at k (P@k)}{15}{subsection.2.3.2}}
\bibstyle{plain}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Normalized Discounted Cumulative Gain (NDCG@20)}{16}{subsection.2.3.3}}
\bibdata{uw-ethesis}
\bibcite{ando2005framework}{1}
\bibcite{nguyen2016msmarco}{2}
\bibcite{belinkov2017neural}{3}
\bibcite{blitzer2006domain}{4}
\bibcite{bojanowski2017enriching}{5}
\bibcite{Cormack:2009:RRF:1571941.1572114}{6}
\bibcite{dai2018convolutional}{7}
\@writefile{toc}{\contentsline {chapter}{\textbf  {References}}{17}{section*.11}}
\bibcite{deerwester1990indexing}{8}
\bibcite{devlin2018bert}{9}
\bibcite{dietz2017trec}{10}
\bibcite{DBLP:journals/corr/abs-1803-11138}{11}
\bibcite{guo2016deep}{12}
\bibcite{guo2017drmm}{13}
\bibcite{huang2013learning}{14}
\bibcite{joachims2002optimizing}{15}
\bibcite{jones2000probabilistic}{16}
\bibcite{lin2019neural}{17}
\bibcite{DBLP:journals/corr/LinzenDG16}{18}
\bibcite{lipton2018troubling}{19}
\bibcite{macavaney2019cedr}{20}
\bibcite{manning2010introduction}{21}
\bibcite{melamud2016context2vec}{22}
\bibcite{mikolov2013distributed}{23}
\bibcite{mitra2017neural}{24}
\bibcite{nogueira2019passage}{25}
\bibcite{Padigela:1905.01758:2019}{26}
\bibcite{padigela2019bert}{27}
\bibcite{pennington2014glove}{28}
\bibcite{peters2018deep}{29}
\bibcite{Qiao:1904.07531:2019}{30}
\bibcite{radford2018improving}{31}
\bibcite{radford2019language}{32}
\bibcite{rajpurkar2016squad}{33}
\bibcite{rao2019tweet}{34}
\bibcite{sculley2018winner}{35}
\bibcite{shen2014learning}{36}
\bibcite{socher2013recursive}{37}
\bibcite{turian2010word}{38}
\bibcite{vaswani2017attention}{39}
\bibcite{wang2018glue}{40}
\bibcite{wu2016google}{41}
\bibcite{xiong2017knrm}{42}
\bibcite{Yang:2018:ARR:3289400.3239571}{43}
\bibcite{Yang_etal_SIGIR2019}{44}
\bibcite{yang2019end}{45}
\bibcite{yang2019simple}{46}
\bibcite{zamani2018neural}{47}
\bibcite{zhang2018effective}{48}
\bibcite{zhao2010term}{49}
\bibcite{zhu2015aligning}{50}
\citation{*}
