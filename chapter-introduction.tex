%======================================================================
\chapter{Introduction}
%======================================================================

Document retrieval refers to the task of generating a ranking of documents from a large corpus $ D $ in response to a query $ Q $.
In a typical document retrieval pipeline, an inverted index is constructed in advance from the collection, which often comprises unstructured text documents, for fast access during retrieval.
When the user issues a query, the query representation is matched against the index, computing a similarity score for each document.
The top most relevant documents based on their closeness to the query are returned to the user in order of relevance.
This procedure may be followed by a subsequent re-ranking stage where the candidate documents outputted by the previous step are further re-ranked in a way that maximizes some retrieval metric such as average precision (AP).

\begin{figure}[b!]
	\begin{framed}
		\centering
    		\textbf{Query:} international art crime \\
    		\textbf{Text:} The thieves demand a ransom of \$2.2 million for the works and return one of them.
	\end{framed}
\label{query-sent-example}
 \caption{An example of a query-text pair from the TREC Robust04 collection where a relevant piece of text does not contain direct query matches.}
\end{figure}

Document retrieval systems traditionally rely on term-matching techniques, such as BM25, to judge the relevance of documents in a corpus.
More specifically, the more common terms a document shares with the query, the more relevant it is considered.
As a result, these systems may fail to detect documents that do not contain the exact query terms, but are nonetheless relevant.
For example, consider a document that expresses relevant information in a way that cannot be resolved without the use of external semantic tools.
Figure \ref{query-sent-example} displays one such query-text pair where words semantically close to the query need to be identified to establish relevance.
This ``vocabulary mismatch'' problem represents a long-standing challenge in information retrieval.
To put its significance into context, Zhao et al. \cite{zhao2010term} show that the average query terms may not appear in as many as 40\% of relevant documents in TREC ``ad hoc'' retrieval datasets.

Clearly, the classic exact matching approach to document retrieval neglects to exploit rich semantic information embedded in the documents.
To overcome this shortcoming, a number of models such as Latent Semantic Analysis \cite{deerwester1990indexing} that maps both queries and documents into distributed representations has been proposed.
This innovation has enabled semantic matching to aid in document retrieval by extracting useful semantic matching signals.
With the advent of neural networks, neural language models have been quickly adopted to learn better distributed representations of text.
\myworries{How much better? Why?}
Moreover, deep neural models have eliminated the need to manually engineer natural language features.
Therefore, deep neural networks have since largely replaced the earlier models based on manual decomposition of document matrices.
\myworries{Examples...}

%Despite growing interest in neural networks, some researchers have recently voiced concern as to whether their use has truly contributed to progress in the field of information retrieval \myworries{citation}.
%\myworries{Take stuff from their neural hype paper}

One recent innovation that has changed the tide in NLP research has been massively pre-trained language models with its most popular example today being Bidirectional Encoder Representation Transformers (BERT) \cite{devlin2018bert}.
BERT has achieved state-of-the-art results across a wide range of NLP tasks from question answering to machine translation.
While BERT has enjoyed widespread adoption across the NLP community, its application in information retrieval research has been limited in comparison.
Guo et al. \cite{guo2016deep} suggest that the lackluster success of deep neural networks in information retrieval may be owing to the fact that crucial characteristics of the ``ad hoc'' document retrieval task are not properly addressed.
Specifically, they emphasize that the relevance matching problem in information retrieval and semantic matching problem in natural language processing are fundamentally different in that the former depends heavily on exact matching signals, query term importance and diverse matching requirements.
In other words, it is crucial to strike a good balance between exact and semantic matching in document retrieval.
For this reason, neural models are usually involved in multi-stage architectures where a list of candidate documents are retrieved with a standard bag-of-words term-matching technique as described above.
The documents in this list are then rescored and reranked by the neural model.
\myworries{Some notable examples include...}

%%%

In this thesis, we present a novel way to apply BERT to ``ad hoc'' document retrieval on long documents -- particularly, newswire articles.
A BERT reranker is deployed as part of an end-to-end document retrieval pipeline with significant improvements on standard TREC newswire collections.
Specifically, we adapt BERT for binary relevance classification over text to capture notions of relevance.
\myworries{One more sentence to describe?}
We point out that applying BERT to document retrieval on newswire documents is not trivial due to two principal challenges.
Firist of all, BERT has a maximum input length of 512 tokens, which is insufficient to accommodate the entirety of most news articles.
To put this into perspective, a typical TREC Robust04 document has a median length of 679 tokens, and in fact, 66\% of all documents are longer than 512 tokens.
Secondly, most collections provide relevance judgements only at the document level.
Therefore, we only know what documents are relevant for a given query, but not the specific spans within the document.
To further aggravate this issue, a document is considered relevant as long as some part of it is relevant, and most of the document often has nothing to do with the query.

We address the abovementioned challenges by proposing two effective innovations:\
First, instead of relying solely on document-level relevance judgements, we aggregate sentence-level evidence to rank documents.
As mentioned before, since standard newswire collections lack sentence level judgements to facilitate this approach, we instead explore leveraging sentence-level or passage-level judgements already available in collections in other domains, such as tweets and reading comprehension.
To this end, we fine-tune BERT models on these collections to learn models of relevance.
Surprisingly, we demonstrate that models of relevance can indeed be successfully transferred across domains.
%We are able to use BERT models trained on out-of-domain collections on newswire documents to compute a relevance score for each constituent sentence.
It is important to note that the representational power of neural networks come at the cost of challenges in interpretability.
For this reason, we dedicate a portion of this thesis to error analysis experiments in an attempt to qualify and better understand the cross-domain transfer effects.
We also elaborate on the challenges encountered in the implementation of such an end-to-end retrieval pipeline in an attempt to bridge the worlds of natural language processing and information retrieval from a software engineering perspective.

\section{Contributions}

The main contributions of this thesis can be summarized as follows:\\

\begin{itemize}
\item
We present two innovations to successfully apply BERT to \textit{ad hoc} document retrieval with large improvements:\
integrating sentence-level evidence to address the fact that BERT cannot process long spans posed by newswire documents, and exploiting cross-domain models of relevance for collections without sentence- or passage-level annotations.
\item
We explore through various error analysis experiments on the effects of cross-domain relevance transfer with BERT as well as the contributions of BM25 and sentence scores to the final document ranking.
\item 
With the proposed model, we establish state-of-the-art effectiveness on three standard TREC newswire collections at the time of writing.\
\myworries{neural or otherwise}
\item
We release an end-to-end pipeline that applies BERT to document retrieval over large document collections via integration with the open-source Anserini information retrieval toolkit.
We elaborate on the technical challenges in the integration of NLP and IR capabilities, along with the design rationale behind our approach to tightly-coupled integration between Python to support neural networks and the Java Virtual Machine to support document retrieval using the open-source Lucene search library.
\myworries{something about demo, TREC DL...}

\end{itemize}

\section{Thesis Organization}

The remainder of this thesis is organized in the following order:\
\myworries{add link to actual chapters}
Chapter 2 reviews related work in neural document retrieval, particularly applications of BERT to document retrieval.
Chapter 3 motivates the approach with some background information on the task, and introduces the datasets used for both training and evaluation as well as metrics.
Chapter 4 proposes an end-to-end pipeline for document retrieval with BERT by elaborating on the design decisions and challenges.
\myworries{What about TREC DL? MS MARCO?}
Chapter 5 describes the experimental setup, and presents the results on three newswire collections -- Robust04, Core17 and Core18.
Chapter 6 concludes the thesis by summarizing the contributions and discussing future work.

%In the beginning, there was $\pi$:
%
%\begin{equation}
%   e^{\pi i} + 1 = 0  \label{eqn_pi}
%\end{equation}
%A \gls{computer} could compute $\pi$ all day long. In fact, subsets of digits of $\pi$'s decimal approximation would make a good source for psuedo-random vectors, \gls{rvec} . 
%
%%----------------------------------------------------------------------
%\section{State of the Art}
%%----------------------------------------------------------------------
%
%See equation \ref{eqn_pi} on page \pageref{eqn_pi}.\footnote{A famous equation.}
%
%\section{Some Meaningless Stuff}
%
%The credo of the \gls{aaaaz} was, for several years, several paragraphs of gibberish, until the \gls{dingledorf} responsible for the \gls{aaaaz} Web site realized his mistake:
%
%"Velit dolor illum facilisis zzril ipsum, augue odio, accumsan ea augue molestie lobortis zzril laoreet ex ad, adipiscing nulla. Veniam dolore, vel te in dolor te, feugait dolore ex vel erat duis nostrud diam commodo ad eu in consequat esse in ut wisi. Consectetuer dolore feugiat wisi eum dignissim tincidunt vel, nostrud, at vulputate eum euismod, diam minim eros consequat lorem aliquam et ad. Feugait illum sit suscipit ut, tation in dolore euismod et iusto nulla amet wisi odio quis nisl feugiat adipiscing luptatum minim nisl, quis, erat, dolore. Elit quis sit dolor veniam blandit ullamcorper ex, vero nonummy, duis exerci delenit ullamcorper at feugiat ullamcorper, ullamcorper elit vulputate iusto esse luptatum duis autem. Nulla nulla qui, te praesent et at nisl ut in consequat blandit vel augue ut.
%
%Illum suscipit delenit commodo augue exerci magna veniam hendrerit dignissim duis ut feugait amet dolor dolor suscipit iriure veniam. Vel quis enim vulputate nulla facilisis volutpat vel in, suscipit facilisis dolore ut veniam, duis facilisi wisi nulla aliquip vero praesent nibh molestie consectetuer nulla. Wisi nibh exerci hendrerit consequat, nostrud lobortis ut praesent dignissim tincidunt enim eum accumsan. Lorem, nonummy duis iriure autem feugait praesent, duis, accumsan tation enim facilisi qui te dolore magna velit, iusto esse eu, zzril. Feugiat enim zzril, te vel illum, lobortis ut tation, elit luptatum ipsum, aliquam dolor sed. Ex consectetuer aliquip in, tation delenit dignissim accumsan consequat, vero, et ad eu velit ut duis ea ea odio.
%
%Vero qui, te praesent et at nisl ut in consequat blandit vel augue ut dolor illum facilisis zzril ipsum. Exerci odio, accumsan ea augue molestie lobortis zzril laoreet ex ad, adipiscing nulla, et dolore, vel te in dolor te, feugait dolore ex vel erat duis. Ut diam commodo ad eu in consequat esse in ut wisi aliquip dolore feugiat wisi eum dignissim tincidunt vel, nostrud. Ut vulputate eum euismod, diam minim eros consequat lorem aliquam et ad luptatum illum sit suscipit ut, tation in dolore euismod et iusto nulla. Iusto wisi odio quis nisl feugiat adipiscing luptatum minim. Illum, quis, erat, dolore qui quis sit dolor veniam blandit ullamcorper ex, vero nonummy, duis exerci delenit ullamcorper at feugiat. Et, ullamcorper elit vulputate iusto esse luptatum duis autem esse nulla qui.
%
%Praesent dolore et, delenit, laoreet dolore sed eros hendrerit consequat lobortis. Dolor nulla suscipit delenit commodo augue exerci magna veniam hendrerit dignissim duis ut feugait amet. Ad dolor suscipit iriure veniam blandit quis enim vulputate nulla facilisis volutpat vel in. Erat facilisis dolore ut veniam, duis facilisi wisi nulla aliquip vero praesent nibh molestie consectetuer nulla, iriure nibh exerci hendrerit. Vel, nostrud lobortis ut praesent dignissim tincidunt enim eum accumsan ea, nonummy duis. Ad autem feugait praesent, duis, accumsan tation enim facilisi qui te dolore magna velit, iusto esse eu, zzril vel enim zzril, te. Nisl illum, lobortis ut tation, elit luptatum ipsum, aliquam dolor sed minim consectetuer aliquip.
%
%Tation exerci delenit ullamcorper at feugiat ullamcorper, ullamcorper elit vulputate iusto esse luptatum duis autem esse nulla qui. Volutpat praesent et at nisl ut in consequat blandit vel augue ut dolor illum facilisis zzril ipsum, augue odio, accumsan ea augue molestie lobortis zzril laoreet. Ex duis, te velit illum odio, nisl qui consequat aliquip qui blandit hendrerit. Ea dolor nonummy ullamcorper nulla lorem tation laoreet in ea, ullamcorper vel consequat zzril delenit quis dignissim, vulputate tincidunt ut."